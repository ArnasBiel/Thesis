{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The following code takes the saved LLM response files, matches the stimuli file to the responses, adds IDs by each LLM conversation, adds context and type, connects the tables and reorders them based on the \"Selected word\" and \"Context\""
      ],
      "metadata": {
        "id": "yhmF0WuUY7cJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6bQZlrKLYtC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StimuliMatcher:\n",
        "    def __init__(self, stimuli_path, interpretation_paths, output_path):\n",
        "        self.stimuli_path = stimuli_path\n",
        "        self.interpretation_paths = interpretation_paths\n",
        "        self.output_path = output_path\n",
        "\n",
        "        self.stimuli_df = pd.read_excel(self.stimuli_path)\n",
        "\n",
        "    def normalize(self, sentence):\n",
        "        \"\"\"Cleans sentence for reliable matching.\"\"\"\n",
        "        return str(sentence).strip().replace('\"', '').replace('[', '').replace(']', '')\n",
        "\n",
        "    def match_and_merge(self, response_df):\n",
        "        \"\"\"Matches a single interpretation file with the stimuli.\"\"\"\n",
        "        merged_rows = []\n",
        "\n",
        "        for _, stim_row in self.stimuli_df.iterrows():\n",
        "            stim_sentence = self.normalize(stim_row['sentence'])\n",
        "\n",
        "            for _, resp_row in response_df.iterrows():\n",
        "                resp_sentence = self.normalize(resp_row['Sentence'])\n",
        "\n",
        "                if stim_sentence == resp_sentence:\n",
        "                    merged_row = resp_row.copy()\n",
        "                    merged_row['Context'] = stim_row['Meaning/context']\n",
        "                    merged_row['Type'] = stim_row['type']  # Note: 'type' becomes 'Type'\n",
        "                    merged_rows.append(merged_row)\n",
        "                    break  # Stop looking once match is found\n",
        "\n",
        "        return merged_rows\n",
        "\n",
        "    def create_augmented_file(self):\n",
        "\n",
        "        all_merged = []\n",
        "\n",
        "        for file_index, path in enumerate(self.interpretation_paths):\n",
        "            \"\"\"Processes all interpretation files and saves combined output.\"\"\"\n",
        "            response_df = pd.read_excel(path)\n",
        "            # Calculate base LLM ID for this file (0-1, 1-13, 2-25, etc.)\n",
        "            base_llm_id = file_index * 12 + 1\n",
        "            # Add LLM_ID column based on row position (every 10 rows get same ID)\n",
        "            response_df['LLM_ID'] = [f'LLM{base_llm_id + (i // 10)}' for i in range(len(response_df))]\n",
        "            matched_rows = self.match_and_merge(response_df)\n",
        "            all_merged.extend(matched_rows)\n",
        "\n",
        "        combined_df = pd.DataFrame(all_merged)\n",
        "\n",
        "        # Reorder by 'Selected Word' and 'Meaning/context' for easier handling\n",
        "        if 'Selected Word' in combined_df.columns:\n",
        "            combined_df.sort_values(by=['Selected Word', 'Context'], inplace=True)\n",
        "\n",
        "        combined_df.to_excel(self.output_path, index=False)\n",
        "        print(f\"Saved combined and reordered file to '{self.output_path}'\")\n",
        "\n",
        "interpretation_paths = [f\"interpretation_results_sentences_{i}.xlsx\" for i in range(1, 6)]\n",
        "\n",
        "matcher = StimuliMatcher(\n",
        "    stimuli_path=\"cleared_stimuli.xlsx\",\n",
        "    interpretation_paths = interpretation_paths,\n",
        "    output_path=\"combined_llm_responses.xlsx\"\n",
        ")\n",
        "\n",
        "matcher.create_augmented_file()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oNAQ-DONkhN",
        "outputId": "2ea6ea1f-3438-43b8-a237-c1761e8f630e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved combined and reordered file to 'combined_llm_responses.xlsx'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearing human responses. Since the human resposne file had a different structure, first it is necessary to create question codes for the question retrieval of each interpretation"
      ],
      "metadata": {
        "id": "TURCEKXTiMpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compound_words = ['jailbird', 'blackmail', 'mushroom', 'claptrap', 'humbug', 'pigeonhole', 'township', 'slapstick', 'chopstick', 'touchstone', 'meantime', 'carpet', 'message', 'chinaware', 'warsaw', 'psychopath', 'airline', 'highlight', 'sidekick', 'rugrat' ]\n",
        "pseudo_words = ['coaster', 'river', 'litter', 'bower', 'flower', 'brother', 'horny', 'busy', 'potage', 'footage', 'petal', 'marshal', 'tactic', 'delight', 'unionizing', 'better', 'undies', 'deliver', 'early', 'summer']\n",
        "all_words = compound_words + pseudo_words\n",
        "\n",
        "code_to_info= {}\n",
        "\n",
        "for i, word in enumerate(all_words):\n",
        "    word_index = (i % 20) + 1  # 1 to 20\n",
        "    prefix = 'c' if i < 20 else 'p'\n",
        "    for context in range(1, 4):\n",
        "        code = f\"{prefix}-{word_index}-{context}\"\n",
        "        code_to_info[code] = {'word': word, 'context': context}\n",
        "print(code_to_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wkWrb82iO1h",
        "outputId": "46e90f56-cf8d-474b-ff07-9d7e40402a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'c-1-1': {'word': 'jailbird', 'context': 1}, 'c-1-2': {'word': 'jailbird', 'context': 2}, 'c-1-3': {'word': 'jailbird', 'context': 3}, 'c-2-1': {'word': 'blackmail', 'context': 1}, 'c-2-2': {'word': 'blackmail', 'context': 2}, 'c-2-3': {'word': 'blackmail', 'context': 3}, 'c-3-1': {'word': 'mushroom', 'context': 1}, 'c-3-2': {'word': 'mushroom', 'context': 2}, 'c-3-3': {'word': 'mushroom', 'context': 3}, 'c-4-1': {'word': 'claptrap', 'context': 1}, 'c-4-2': {'word': 'claptrap', 'context': 2}, 'c-4-3': {'word': 'claptrap', 'context': 3}, 'c-5-1': {'word': 'humbug', 'context': 1}, 'c-5-2': {'word': 'humbug', 'context': 2}, 'c-5-3': {'word': 'humbug', 'context': 3}, 'c-6-1': {'word': 'pigeonhole', 'context': 1}, 'c-6-2': {'word': 'pigeonhole', 'context': 2}, 'c-6-3': {'word': 'pigeonhole', 'context': 3}, 'c-7-1': {'word': 'township', 'context': 1}, 'c-7-2': {'word': 'township', 'context': 2}, 'c-7-3': {'word': 'township', 'context': 3}, 'c-8-1': {'word': 'slapstick', 'context': 1}, 'c-8-2': {'word': 'slapstick', 'context': 2}, 'c-8-3': {'word': 'slapstick', 'context': 3}, 'c-9-1': {'word': 'chopstick', 'context': 1}, 'c-9-2': {'word': 'chopstick', 'context': 2}, 'c-9-3': {'word': 'chopstick', 'context': 3}, 'c-10-1': {'word': 'touchstone', 'context': 1}, 'c-10-2': {'word': 'touchstone', 'context': 2}, 'c-10-3': {'word': 'touchstone', 'context': 3}, 'c-11-1': {'word': 'meantime', 'context': 1}, 'c-11-2': {'word': 'meantime', 'context': 2}, 'c-11-3': {'word': 'meantime', 'context': 3}, 'c-12-1': {'word': 'carpet', 'context': 1}, 'c-12-2': {'word': 'carpet', 'context': 2}, 'c-12-3': {'word': 'carpet', 'context': 3}, 'c-13-1': {'word': 'message', 'context': 1}, 'c-13-2': {'word': 'message', 'context': 2}, 'c-13-3': {'word': 'message', 'context': 3}, 'c-14-1': {'word': 'chinaware', 'context': 1}, 'c-14-2': {'word': 'chinaware', 'context': 2}, 'c-14-3': {'word': 'chinaware', 'context': 3}, 'c-15-1': {'word': 'warsaw', 'context': 1}, 'c-15-2': {'word': 'warsaw', 'context': 2}, 'c-15-3': {'word': 'warsaw', 'context': 3}, 'c-16-1': {'word': 'psychopath', 'context': 1}, 'c-16-2': {'word': 'psychopath', 'context': 2}, 'c-16-3': {'word': 'psychopath', 'context': 3}, 'c-17-1': {'word': 'airline', 'context': 1}, 'c-17-2': {'word': 'airline', 'context': 2}, 'c-17-3': {'word': 'airline', 'context': 3}, 'c-18-1': {'word': 'highlight', 'context': 1}, 'c-18-2': {'word': 'highlight', 'context': 2}, 'c-18-3': {'word': 'highlight', 'context': 3}, 'c-19-1': {'word': 'sidekick', 'context': 1}, 'c-19-2': {'word': 'sidekick', 'context': 2}, 'c-19-3': {'word': 'sidekick', 'context': 3}, 'c-20-1': {'word': 'rugrat', 'context': 1}, 'c-20-2': {'word': 'rugrat', 'context': 2}, 'c-20-3': {'word': 'rugrat', 'context': 3}, 'p-1-1': {'word': 'coaster', 'context': 1}, 'p-1-2': {'word': 'coaster', 'context': 2}, 'p-1-3': {'word': 'coaster', 'context': 3}, 'p-2-1': {'word': 'river', 'context': 1}, 'p-2-2': {'word': 'river', 'context': 2}, 'p-2-3': {'word': 'river', 'context': 3}, 'p-3-1': {'word': 'litter', 'context': 1}, 'p-3-2': {'word': 'litter', 'context': 2}, 'p-3-3': {'word': 'litter', 'context': 3}, 'p-4-1': {'word': 'bower', 'context': 1}, 'p-4-2': {'word': 'bower', 'context': 2}, 'p-4-3': {'word': 'bower', 'context': 3}, 'p-5-1': {'word': 'flower', 'context': 1}, 'p-5-2': {'word': 'flower', 'context': 2}, 'p-5-3': {'word': 'flower', 'context': 3}, 'p-6-1': {'word': 'brother', 'context': 1}, 'p-6-2': {'word': 'brother', 'context': 2}, 'p-6-3': {'word': 'brother', 'context': 3}, 'p-7-1': {'word': 'horny', 'context': 1}, 'p-7-2': {'word': 'horny', 'context': 2}, 'p-7-3': {'word': 'horny', 'context': 3}, 'p-8-1': {'word': 'busy', 'context': 1}, 'p-8-2': {'word': 'busy', 'context': 2}, 'p-8-3': {'word': 'busy', 'context': 3}, 'p-9-1': {'word': 'potage', 'context': 1}, 'p-9-2': {'word': 'potage', 'context': 2}, 'p-9-3': {'word': 'potage', 'context': 3}, 'p-10-1': {'word': 'footage', 'context': 1}, 'p-10-2': {'word': 'footage', 'context': 2}, 'p-10-3': {'word': 'footage', 'context': 3}, 'p-11-1': {'word': 'petal', 'context': 1}, 'p-11-2': {'word': 'petal', 'context': 2}, 'p-11-3': {'word': 'petal', 'context': 3}, 'p-12-1': {'word': 'marshal', 'context': 1}, 'p-12-2': {'word': 'marshal', 'context': 2}, 'p-12-3': {'word': 'marshal', 'context': 3}, 'p-13-1': {'word': 'tactic', 'context': 1}, 'p-13-2': {'word': 'tactic', 'context': 2}, 'p-13-3': {'word': 'tactic', 'context': 3}, 'p-14-1': {'word': 'delight', 'context': 1}, 'p-14-2': {'word': 'delight', 'context': 2}, 'p-14-3': {'word': 'delight', 'context': 3}, 'p-15-1': {'word': 'unionizing', 'context': 1}, 'p-15-2': {'word': 'unionizing', 'context': 2}, 'p-15-3': {'word': 'unionizing', 'context': 3}, 'p-16-1': {'word': 'better', 'context': 1}, 'p-16-2': {'word': 'better', 'context': 2}, 'p-16-3': {'word': 'better', 'context': 3}, 'p-17-1': {'word': 'undies', 'context': 1}, 'p-17-2': {'word': 'undies', 'context': 2}, 'p-17-3': {'word': 'undies', 'context': 3}, 'p-18-1': {'word': 'deliver', 'context': 1}, 'p-18-2': {'word': 'deliver', 'context': 2}, 'p-18-3': {'word': 'deliver', 'context': 3}, 'p-19-1': {'word': 'early', 'context': 1}, 'p-19-2': {'word': 'early', 'context': 2}, 'p-19-3': {'word': 'early', 'context': 3}, 'p-20-1': {'word': 'summer', 'context': 1}, 'p-20-2': {'word': 'summer', 'context': 2}, 'p-20-3': {'word': 'summer', 'context': 3}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#!pip install openpyxl\n",
        "\n",
        "class HumanResponseProcessor:\n",
        "    def __init__(self, response_file, code_to_info, compound_words, pseudo_words):\n",
        "        self.response_file = response_file\n",
        "        self.code_to_info = code_to_info\n",
        "        self.compound_words = set(compound_words)\n",
        "        self.pseudo_words = set(pseudo_words)\n",
        "\n",
        "    def transform_responses(self):\n",
        "        df = pd.read_excel(self.response_file)\n",
        "\n",
        "        # Drop the second row (usually question text, not actual data)\n",
        "        df = df.drop(index=0).reset_index(drop=True)\n",
        "\n",
        "        results = []\n",
        "        for code, info in self.code_to_info.items():\n",
        "            if code not in df.columns:\n",
        "                continue\n",
        "\n",
        "            confidence_col = code + '-c_1'\n",
        "\n",
        "            for row_idx, row in df.iterrows():\n",
        "                interpretation = row.get(code)\n",
        "                confidence = row.get(confidence_col, None)\n",
        "\n",
        "                if pd.notna(interpretation):\n",
        "                    results.append({\n",
        "                        \"Participant ID\": row_idx + 1, # Add a row index as a participants ID since all the data is saved as a row for each participant\n",
        "                        \"Selected word\": info['word'],\n",
        "                        \"Interpretation\": interpretation,\n",
        "                        \"Confidence\": confidence,\n",
        "                        \"Context\": info['context']\n",
        "                    })\n",
        "\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "    def clean_and_label(self, df):\n",
        "        # Add \"Type\" based on word\n",
        "        def get_word_type(word):\n",
        "            if word in self.compound_words:\n",
        "                return \"compound\"\n",
        "            elif word in self.pseudo_words:\n",
        "                return \"pseudo-derived\"\n",
        "            else:\n",
        "                return \"unknown\"\n",
        "\n",
        "        df[\"Type\"] = df[\"Selected word\"].apply(get_word_type)\n",
        "\n",
        "        # Clean \"Confidence\"\n",
        "        def clean_confidence(val):\n",
        "            if pd.isna(val):\n",
        "                return None\n",
        "            val_str = str(val).strip()\n",
        "            return int(val_str[0]) if val_str and val_str[0].isdigit() else None\n",
        "\n",
        "        df[\"Confidence\"] = df[\"Confidence\"].apply(clean_confidence)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def process_and_save(self, output_path):\n",
        "        df_transformed = self.transform_responses()\n",
        "        df_cleaned = self.clean_and_label(df_transformed)\n",
        "        df_cleaned.to_excel(output_path, index=False)\n",
        "        print(f\"Final cleaned responses saved to: {output_path}\")\n",
        "\n",
        "# Process the file\n",
        "processor = HumanResponseProcessor(\n",
        "    response_file=\"Novel+word+survey_April+11,+2025_19.54.xlsx\",\n",
        "    code_to_info=code_to_info,\n",
        "    compound_words=compound_words,\n",
        "    pseudo_words=pseudo_words\n",
        ")\n",
        "\n",
        "processor.process_and_save(\"final_human_responses.xlsx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJrfffBHiQV9",
        "outputId": "64910f8a-c3ac-460a-eea6-77341e6b3f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final cleaned responses saved to: final_human_responses.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is for getting similarity scores for the cleared data"
      ],
      "metadata": {
        "id": "LassRccOYtu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import itertools"
      ],
      "metadata": {
        "id": "AntYVvcoVARg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarity scores of Target/golden interpretation vs. LLM/Human interpretations"
      ],
      "metadata": {
        "id": "d_sm-ONOY96q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC3DMljRJBZ-",
        "outputId": "07619512-b640-411b-d242-34e5f9cb5332"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done! Saved similarity scores.\n"
          ]
        }
      ],
      "source": [
        "# Load model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Choose the correct file\n",
        "human_response_path = \"final_human_responses.xlsx\"\n",
        "llm_response_path = \"combined_llm_responses_with_IDs_cleared.xlsx\"#\"final_llm_responses.xlsx\"\n",
        "human_output_path = \"final_human_responses_with_scores.xlsx\"\n",
        "llm_output_path = \"final_llm_responses_with_scores.xlsx\"\n",
        "\n",
        "chosen_response_path = llm_response_path #Change the desired path here\n",
        "chosen_output_path = llm_output_path\n",
        "\n",
        "# Load files\n",
        "stimuli_df = pd.read_excel(\"cleared_stimuli.xlsx\")\n",
        "df = pd.read_excel(chosen_response_path) #Input the path given the task\n",
        "\n",
        "# Initialize a new column\n",
        "df[\"InterpretationScore\"] = None\n",
        "\n",
        "# Go through each golden interpretation\n",
        "for _, stim_row in stimuli_df.iterrows():\n",
        "    if stim_row[\"Meaning/context\"] != \"New\":\n",
        "        continue\n",
        "\n",
        "    golden_sentence = stim_row[\"sentence\"]\n",
        "    target_word = stim_row[\"word\"]\n",
        "\n",
        "    # Embed golden sentence once\n",
        "    golden_emb = model.encode(golden_sentence, convert_to_tensor=True)\n",
        "\n",
        "    # Find matching LLM responses\n",
        "    mask = df[\"Selected word\"] == target_word\n",
        "    for idx, row in df[mask].iterrows():\n",
        "        interpretation = row[\"Interpretation\"]\n",
        "\n",
        "        # Handle empty interpretations\n",
        "        if pd.isna(interpretation) or not interpretation.strip():\n",
        "            continue\n",
        "\n",
        "        interp_emb = model.encode(interpretation, convert_to_tensor=True)\n",
        "        similarity = util.cos_sim(golden_emb, interp_emb).item()\n",
        "\n",
        "        # Save score to dataframe\n",
        "        df.at[idx, \"InterpretationScore\"] = similarity\n",
        "\n",
        "# Save the updated responses file\n",
        "df.to_excel(chosen_output_path, index=False)\n",
        "print(\"Done! Saved similarity scores.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code in case some sentences do not get scored (There were a couple sentences that have not been recorded correctly for LLMs)"
      ],
      "metadata": {
        "id": "XA3d5k3pY80a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "golden_sentence= \"A humming insect\"\n",
        "interpretation = [\"refers to deceptive or false talk or behavior, often causing distraction or confusion.\", \"refers to something deceptive, fake, or misleading, often causing distraction or frustration.\", \" refers to something deceptive, false, or misleading, often causing distraction or confusion.\"]\n",
        "# Embed golden sentence once\n",
        "golden_emb = model.encode(golden_sentence, convert_to_tensor=True)\n",
        "for inter in interpretation:\n",
        "  interp_emb = model.encode(inter, convert_to_tensor=True)\n",
        "  similarity = util.cos_sim(golden_emb, interp_emb).item()\n",
        "  print(similarity)"
      ],
      "metadata": {
        "id": "ioTRCFlbASgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f06e9b4-1ecf-401c-a14e-96a337fc9a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09745556116104126\n",
            "0.08139339089393616\n",
            "0.06485657393932343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pairwise scores for interpretation between the LLM responses for the same context"
      ],
      "metadata": {
        "id": "6rxgXowIB1ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Load the Excel file (already with AccuracyScore)\n",
        "df = pd.read_excel(\"final_llm_responses_with_scores.xlsx\")\n",
        "\n",
        "# Add new column\n",
        "df[\"AvgCohesion\"] = None\n",
        "\n",
        "# Go through the DataFrame in blocks of 5 since there are 5 responses per Context-Word combination\n",
        "for i in range(0, len(df), 5):\n",
        "    block = df.iloc[i:i+5]\n",
        "\n",
        "    # Skip incomplete groups\n",
        "    if len(block) < 5:\n",
        "        continue\n",
        "\n",
        "    interpretations = block[\"Interpretation\"].tolist()\n",
        "\n",
        "    # Encode all 5 interpretations\n",
        "    embeddings = model.encode(interpretations, convert_to_tensor=True)\n",
        "\n",
        "    # Generate all 10 unique pairwise combinations (each sentence is matched once with every other sentence)\n",
        "    pairs = list(itertools.combinations(range(5), 2))\n",
        "    scores = [util.cos_sim(embeddings[i], embeddings[j]).item() for i, j in pairs]\n",
        "\n",
        "    avg_score = sum(scores) / len(scores)\n",
        "\n",
        "    # Assign the same score to all 5 rows for easier data managing\n",
        "    df.loc[i:i+4, \"AvgCohesion\"] = avg_score\n",
        "\n",
        "# Save final file\n",
        "df.to_excel(\"final_llm_responses_with_scores_and_cohesion.xlsx\", index=False)\n",
        "print(\"All AvgCohesion scores computed and saved.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "224uVx4GY8Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ZaoHd9Gh9dJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}